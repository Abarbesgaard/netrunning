---
{"dg-publish":true,"permalink":"/main/ai/guide-til-prompt-engineering/","tags":["Prompts","Ai"],"dgHomeLink":"false","dgShowFileTree":"false","dgEnableSearch":"false","created":"2024-12-02T08:19:33.214+01:00"}
---

## Hvad er prompt engineering

Prompt engineering er et nyt område, hvor man udvikler og forbedrer prompts for at få mest muligt ud af sproglige modeller ([[Main/Noter/Large language model\|Large language model]], LLMs). Det bruges til mange forskellige formål og forskningsprojekter. Med gode færdigheder inden for prompt engineering kan man bedre forstå, hvad store sproglige modeller ([[Main/Noter/Large language model\|LLMs]]) kan – *og ikke kan.*

Forskere bruger prompt engineering til at forbedre [[Main/Noter/Large language model\|LLMers]] evner inden for opgaver som at besvare spørgsmål og løse matematiske problemer. Udviklere bruger det til at skabe effektive teknikker, der fungerer sammen med [[Main/Noter/Large language model\|LLM'er]] og andre værktøjer.

## Hvad dækker prompt engineering

Det handler ikke kun om at lave prompts, men også om at opbygge færdigheder og teknikker til at arbejde med [[Main/Noter/Large language model\|LLM'er]]. Med prompt engineering kan du:

- Forstå og udnytte [[Main/Noter/Large language model\|LLM'ers]]muligheder bedre.
- Forbedre sikkerheden ved brug af [[Main/Noter/Large language model\|LLM'er]].
- Udvikle nye funktioner, f.eks. ved at integrere [[Main/Noter/Large language model\|LLM'ers]] med viden fra specifikke områder eller eksterne værktøjer.

Klik her for at gå til:
[[Main/Ai/Introduktion til Prompt engineering\|Introduktion til Prompt engineering]]