---
{"dg-publish":true,"permalink":"/publishing/main/ai/prompt-hacking/introduction/","dgHomeLink":"false","dgShowBacklinks":"false","dgShowFileTree":"false","dgEnableSearch":"false","created":"2024-12-05T07:58:38.325+01:00"}
---


> [!important] Forestil dig
> At en angriber får adgang til den præcise prompt, der bruges til at generere følsomme data som personlige oplysninger eller sikkerhedsprotokoller – hvordan kunne det blive udnyttet mod dig? Og hvordan vil en sådan prompt se ud?

Prompt-hacking er et begreb, der bruges til at beskrive angreb, som udnytter sårbarheder i store sprogmodeller ([[Publishing/Main/Noter/Ai/Large language model\|LLM'er]]) ved at manipulere deres input eller prompts. I modsætning til traditionel hacking, der typisk udnytter software-sårbarheder, er prompt-hacking baseret på nøje udformede prompts for at narre [[Publishing/Main/Noter/Ai/Large language model\|LLM'en]] til at udføre utilsigtede handlinger.

Der er tre typer af prompt-hacking: *prompt-injektion*, *prompt-leak* og *jailbreaking*. Hver type relaterer sig til lidt forskellige sårbarheder og angrebsmetoder, men de har alle det samme grundprincip, nemlig at manipulere [[Publishing/Main/Noter/Ai/Large language model\|LLM'ens]] prompt for at fremkalde uønsket output.

For at beskytte mod prompt-hacking skal der træffes defensive foranstaltninger. Disse omfatter implementering af *prompt-baserede forsvar*, regelmæssig overvågning af  [[Publishing/Main/Noter/Ai/Large language model\|LLM'ens]]  adfærd og output for unormal aktivitet samt brug af finjustering eller andre teknikker. Alt i alt er prompt-hacking en voksende bekymring for sikkerheden af  [[Publishing/Main/Noter/Ai/Large language model\|LLM'er]]  og det er vigtigt at forblive opmærksom og tage proaktive skridt for at beskytte mod denne type angreb.

| File | Title |
| ---- | ----- |

{ .block-language-dataview}
## Kilder
> [!source]- Prompt hacking
> Tilgængelig på: [learnprompting](https://learnprompting.org/docs/prompt_hacking/introduction)

> [!source]- The Rise of a New Threat: Prompt Hacking  
> Tilgængelig på: [promptengineering.org](https://promptengineering.org/the-rise-of-a-new-threat-prompt-hacking/)

> [!source]- Decoding Prompt Hacking: Unveiling the Hidden Power of AI  
> Tilgængelig på: [medium.com](https://medium.com/@itsamruth/decoding-prompt-hacking-unveiling-the-hidden-power-of-ai-part-1-4a6cc1120596)

> [!source]- How to Protect Against Prompt Hacking  
> Tilgængelig på: [prompthub.us](https://www.prompthub.us/blog/how-to-protect-against-prompt-hacking)